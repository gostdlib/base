/*
Package fan provides a way to fan out data to be processed and then fan in the results onto an output channel.
This replaces the normal Go concurrency pattern that can easily deadlock. It also provides support for
using a sync.Group to manage the goroutines that is tied into worker pools.

Here is an example of how to use the fan package:

	// This generates the input to be fanned out. It simply calls the passed Exec to send the data for processing.
	// You could also read input from a file, a database, channel, ...
	in := func(f *Exec[int, string]) {
		for i := 0; i < 10; i++ {
			f.Send(ctx, i)
		}
	}

	// This processes an input and returns the output or an error.
	proc := func(ctx context.Context, in int) (string, error) {
		return strconv.Itoa(in), nil
	}

	// This fans out data generated by "in" to be processed by "proc" and then fans in to the outCh.
	oi := OutIn[int, string]{Input: in, Processor: proc}

	out, err := oi.Run(ctx)
	if err != nil {
	  return err
	}

	// Print the results. The output channel is automatically closed when the processing is done.
	// You must consume all output.
	for r := range out {
		fmt.Println(r.V)
	}

In addition, if you need make sure the order of output matches the order of input, you can set RetainOrder to true.
Read the documentation for RetainOrder for more information.
*/
package fan

import (
	"context"
	"errors"
	"sync/atomic"

	"github.com/gostdlib/base/concurrency/sync"
)

// Response is a response to some type of call that contains a value and an error.
// TODO: When 1.24 is released, replace this with a type alias to generics/common.Response .
type Response[T any] struct {
	// V is the value.
	V T
	// Err is the error.
	Err error
}

// Exec is used in Args.Input to send data to the Fanner.
type Exec[InT any, OutT any] struct {
	fanner *fanner[InT, OutT]

	nextIndex atomic.Int64
	nextSend  atomic.Int64

	mu      sync.Mutex // protect ordered
	ordered map[int64]Response[OutT]
}

// Send is used to send data to be fanned out for parallel processing.
// Send is thread-safe and can be called from multiple goroutines.
func (f *Exec[I, O]) Send(ctx context.Context, in I) {
	index := f.nextIndex.Add(1) - 1
	f.fanner.outIn.Group.Go(
		ctx,
		func(ctx context.Context) error {
			v, err := f.fanner.outIn.Processor(ctx, in)
			if f.ordered == nil {
				return f.sendUnordered(ctx, v, err)
			}

			// We are retaining order.
			if index == f.nextSend.Load() {
				select {
				case <-ctx.Done():
					return context.Cause(ctx)
				case f.fanner.output <- Response[O]{V: v, Err: err}:
					f.nextSend.Add(1)
					f.drain(ctx)
					return err
				}
			}
			f.mu.Lock()
			f.ordered[index] = Response[O]{V: v, Err: err}
			f.mu.Unlock()
			f.drain(ctx)
			return context.Cause(ctx)
		},
	)
}

func (f *Exec[I, O]) sendUnordered(ctx context.Context, out O, err error) error {
	select {
	case <-ctx.Done():
		return context.Cause(ctx)
	case f.fanner.output <- Response[O]{V: out, Err: err}:
		return err
	}
}

// drain is used to drain our map of responses if we are retaining order.
func (f *Exec[I, O]) drain(ctx context.Context) {
	f.mu.Lock()
	defer f.mu.Unlock()

	// This indicates nothing to do.
	if f.ordered == nil {
		return
	}

	for {
		if v, ok := f.ordered[f.nextSend.Load()]; ok {
			select {
			case <-ctx.Done():
				return
			case f.fanner.output <- v:
				delete(f.ordered, f.nextSend.Load())
				f.nextSend.Add(1)
				continue
			}
		}
		return
	}
}

// OutIn provides a type for running a fan-out/fan-in pattern. This can be reused once the output channel
// is closed from a Run() call. If reusing the OutIn, make sure to replace .Input if the function cannot
// be reused.
type OutIn[I any, O any] struct {
	// Group is the Group to use for the Fanner. Optional.
	Group *sync.Group
	// Input is the function that generates the input for the Fanner. It takes in a FanExec and uses
	// Go() to submit input. Required.
	Input func(f *Exec[I, O])
	// Processor is the function that processes the input from the Fanner. It takes in the input and
	// puts the output on the output channel. Required.
	Processor func(ctx context.Context, in I) (O, error)

	// RetainOrder can be set to cause the order of output objects to match the order of input objects.
	// This will cause delays in the output channel if the next output object is not ready. This can really
	// slow things down data coming from the output channel if the processor is slow to return the next
	// piece of data due to some reason like slow processing or retries. So if order is not important,
	// you should not set this to true. One other note, if the next items gets stuck for a long time, this can
	// build up memory usage as we have to store the next values.
	RetainOrder bool
}

func (f *OutIn[I, O]) validate() error {
	if f.Input == nil {
		return errors.New("Input cannot be nil")
	}
	if f.Processor == nil {
		return errors.New("Processor cannot be nil")
	}
	if f.Group == nil {
		f.Group = &sync.Group{}
	}
	return nil
}

type runOpts struct {
	cancelOnErr bool
}

// RunOption is an option for Run().
type RunOption func(runOpts) (runOpts, error)

// Run runs the fan-out/fan-in pattern. You must process data on the output channel after
// calling this until it closes. Otherwise you can get a deadlock. An error is returned only
// if the OutIn fields do not validate or options are not valid. Otherwise, errors in processing
// are sent to the output channel.
func (o *OutIn[I, O]) Run(ctx context.Context, options ...RunOption) (chan Response[O], error) {
	if err := o.validate(); err != nil {
		return nil, err
	}

	opts := runOpts{}
	for _, option := range options {
		var err error
		opts, err = option(opts)
		if err != nil {
			return nil, err
		}
	}

	f := &fanner[I, O]{
		outIn:  o,
		output: make(chan Response[O], 1),
	}

	var orderQueue map[int64]Response[O]
	if o.RetainOrder {
		orderQueue = make(map[int64]Response[O])
	}

	// Uses a naked goroutine instead of a Group.Pool because the Pool could be some sort of
	// limited pool that would block this. We want to use that Pool exclusively for the processing of the data.
	go func() {
		defer f.close(ctx)
		f.outIn.Input(&Exec[I, O]{fanner: f, ordered: orderQueue})
	}()
	return f.output, nil
}

// fanner adapts a Group to allow for fan-out/fan-in patterns.
type fanner[I any, O any] struct {
	outIn  *OutIn[I, O]
	output chan Response[O]
}

// close spins off a goroutine that waits for all the goroutines called via FanExec.Go() to finish and then
// closes the output channel. OutIn.Submit() should not be called after Close() is called.
func (f *fanner[I, O]) close(ctx context.Context) {
	// Uses a naked goroutine instead of a Group.Pool because the Pool could be some sort of
	// limited pool that would block this.
	go func() {
		f.outIn.Group.Wait(ctx)
		close(f.output)
		return
	}()
}
